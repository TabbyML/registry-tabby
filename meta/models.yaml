- name: StarCoder-3B
  provider_url: https://huggingface.co/bigcode/starcoderbase-3b
  <<: &starcoder-series
    license_name: BigCode-OpenRAIL-M
    license_url: https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement
    prompt_template: "<fim_prefix>{prefix}<fim_suffix>{suffix}<fim_middle>"
  <<: *starcoder-series
  urls:
  - https://huggingface.co/TabbyML/StarCoder-3B/resolve/main/ggml/q8_0.v2.gguf
  - https://modelscope.cn/api/v1/models/TabbyML/StarCoder-3B/repo?FilePath=ggml/q8_0.v2.gguf
  sha256: 9798b7cba84ade7c69ff9f033d60c954e16b18f4d01829993b5fe7e33a49ba81


- name: DeepseekCoder-1.3B
  <<: &deepseek-series
    license_name: Deepseek License
    license_url: https://github.com/deepseek-ai/deepseek-coder/blob/main/LICENSE-MODEL
    prompt_template: "<｜fim▁begin｜>{prefix}<｜fim▁hole｜>{suffix}<｜fim▁end｜>"

  <<: *deepseek-series
  provider_url: https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-instruct
  urls:
  - https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GGUF/resolve/main/deepseek-coder-1.3b-instruct.Q8_0.gguf
  sha256: 36eb025121a50ee6d37fe900659393ff8fb5ea34adc0e3c11fc635e07624dcdb

- name: DeepseekCoder-5.7bmqa-base-Q8_0
  <<: *deepseek-series
  provider_url: https://huggingface.co/deepseek-ai/deepseek-coder-5.7bmqa-base
  urls:
  - https://huggingface.co/TheBloke/deepseek-coder-5.7bmqa-base-GGUF/resolve/main/deepseek-coder-5.7bmqa-base.Q8_0.gguf
  sha256: c6f97ac11bf59bd217ac0d42060ad0af07c23ef48c287345937cd26cd8738dfa


- name: DeepseekCoder-6.7B-instruct-Q6_K
  <<: *deepseek-series
  provider_url: https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct
  urls:
  - https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-GGUF/resolve/main/deepseek-coder-6.7b-instruct.Q6_K.gguf
  sha256: 113fba500e4feb1313ce80d72cf381330b51460d265a7719bba626d6a461f9eb


- name: OpenLlama-3B-instruct-V2-Q6_K
  provider_url: https://huggingface.co/codellama/CodeLlama-7b-hf
  <<: &codellama-series
    license_name: Apache 2.0
    license_url: https://choosealicense.com/licenses/apache-2.0/
    prompt_template: "<PRE> {prefix} <SUF>{suffix} <MID>"
    # prompt_template: "### HUMAN:\n{prompt}\n\n### RESPONSE:\n"
  <<: *codellama-series
  urls:
  - https://huggingface.co/TheBloke/open-llama-3b-v2-wizard-evol-instuct-v2-196k-GGUF/resolve/main/open-llama-3b-v2-wizard-evol-instuct-v2-196k.Q6_K.gguf
  sha256: 19391e5cc3edda035a029a1a9fae04d3c3459f0a6a49ec3559569ff84cd1c002


- name: OpenLlama-3B-instruct-V2-Q8_0
  provider_url: https://huggingface.co/codellama/CodeLlama-7b-hf
  <<: &codellama-series
    license_name: Apache 2.0
    license_url: https://choosealicense.com/licenses/apache-2.0/
    prompt_template: "<PRE> {prefix} <SUF>{suffix} <MID>"
    # prompt_template: "### HUMAN:\n{prompt}\n\n### RESPONSE:\n"
  <<: *codellama-series
  urls:
  - https://huggingface.co/TheBloke/open-llama-3b-v2-wizard-evol-instuct-v2-196k-GGUF/resolve/main/open-llama-3b-v2-wizard-evol-instuct-v2-196k.Q8_0.gguf
  sha256: 07bf92495e6310bc343e116089c5c656caf2e8ee479d30eec2804d5a685cc496


# CHAT MODELS
  
- name: OpenHermes-2.5-Mistral-7B
  <<: &mistral-series
    license_name: Apache 2.0
    license_url: https://choosealicense.com/licenses/apache-2.0/
    chat_template: "<s>{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + '</s> ' }}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}"
  <<: *mistral-series
  provider_url: https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B
  urls:
  - https://huggingface.co/TheBloke/OpenHermes-2.5-Mistral-7B-GGUF/resolve/main/openhermes-2.5-mistral-7b.Q8_0.gguf
  sha256: 1edb516ae5274cf70183d15a6c108e4181fcc318303802a419fd111629b5ca3a

- name: Open_Gpt4_8x7B_v0.2-Q6_K
  <<: &gpt-series
    license_name: Apache 2.0
    license_url: https://choosealicense.com/licenses/apache-2.0/
    chat_template: "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '### Instruction:\n' + message['content'] + '\n### Response:\n' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + '\n' }}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}"
  <<: *gpt-series
  provider_url: https://huggingface.co/rombodawg/Open_Gpt4_8x7B_v0.2
  urls:
  # - file:///models/open_gpt4_8x7b_v0.2.Q6_K.gguf # since this file is massive I am going to download one of them and just have two urls
  - https://huggingface.co/TheBloke/Open_Gpt4_8x7B_v0.2-GGUF/resolve/main/open_gpt4_8x7b_v0.2.Q6_K.gguf
  sha256: 661b0c46852b28547d2abc8eb4472cae9e48ea34fad4304ccf4a0c3b404c3a25
